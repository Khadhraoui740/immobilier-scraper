# ğŸ  SystÃ¨me Complet de Scraping Immobilier

Un systÃ¨me de scraping automatisÃ© et avancÃ© pour trouver des propriÃ©tÃ©s immobiliÃ¨res rÃ©pondant Ã  vos critÃ¨res sur plusieurs plateformes franÃ§aises avec alertes email.

## âœ¨ FonctionnalitÃ©s

- **ğŸ” Scraping multi-plateforme**: SeLoger, PAP, LeBonCoin
- **ğŸ“Š Base de donnÃ©es SQLite** : Stockage persistant et requÃªtes avancÃ©es
- **ğŸ“§ Alertes email automatiques** : Notifications pour les nouvelles annonces
- **â° Planification automatique** : Scraping rÃ©gulier et rapports quotidiens
- **ğŸ’¾ Historique complet** : Suivi des modifications de prix et statuts
- **ğŸ¯ Filtrage avancÃ©** : Budget, DPE, localisation, surface, etc.
- **ğŸ“± CLI intuitive** : Gestion complÃ¨te depuis la ligne de commande
- **ğŸ“ˆ Statistiques dÃ©taillÃ©es** : Analyse des donnÃ©es scrapÃ©es

## ğŸ“‹ CritÃ¨res de Recherche

- **Budget** : 200 000 â‚¬ - 500 000 â‚¬
- **Zones** : Paris (75), Hauts-de-Seine (92), Val-de-Marne (94)
- **DPE max** : D
- **Email de notification** : khadhraoui.jalel@gmail.com

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- pip
- Un compte Gmail avec authentification par mot de passe d'application

### Ã‰tapes d'installation

1. **Cloner/crÃ©er le projet**
```bash
cd C:\Users\jaleleddinekhadhraou\immobilier-scraper
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
venv\Scripts\activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement**
```bash
# Copier le fichier d'exemple
copy .env.example .env

# Ã‰diter .env avec vos paramÃ¨tres
# ParticuliÃ¨rement: EMAIL_PASSWORD (mot de passe d'application Gmail)
```

### Configuration Email Gmail

1. Activer l'authentification 2FA dans votre compte Google
2. CrÃ©er un mot de passe d'application: https://myaccount.google.com/apppasswords
3. Copier le mot de passe dans le fichier `.env` sous `EMAIL_PASSWORD`

## ğŸ“– Utilisation

### Scraping Manuel

```bash
# Scraper toutes les plateformes
python main.py

# Scraper une plateforme spÃ©cifique
python cli.py scrape seloger
python cli.py scrape pap
python cli.py scrape leboncoin
```

### Planification Automatique

```bash
# DÃ©marrer le planificateur (scraping toutes les 2 heures + rapport quotidien)
python scheduler.py
```

### Interface CLI

```bash
# Lister les propriÃ©tÃ©s
python cli.py list
python cli.py list --status disponible --limit 20

# Afficher les statistiques
python cli.py stats

# GÃ©rer les favoris
python cli.py favorite --add <property_id>
python cli.py favorite --list

# Mettre Ã  jour les statuts
python cli.py status --set <property_id> contactÃ©
python cli.py status --list

# Envoyer des alertes
python cli.py email --send --new
python cli.py email --send --report

# Afficher l'aide
python cli.py help
```

## ğŸ“ Structure du Projet

```
immobilier-scraper/
â”œâ”€â”€ config.py                 # Configuration centralisÃ©e
â”œâ”€â”€ logger.py                 # Gestion des logs
â”œâ”€â”€ main.py                   # Script principal de scraping
â”œâ”€â”€ scheduler.py              # Planificateur automatisÃ©
â”œâ”€â”€ cli.py                    # Interface en ligne de commande
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ .env.example              # Exemple de configuration
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db.py                 # Gestion de la base de donnÃ©es
â”‚   â”œâ”€â”€ immobilier.db         # Base de donnÃ©es SQLite
â”‚   â””â”€â”€ backups/              # Sauvegardes de la BD
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py       # Classe de base abstraite
â”‚   â”œâ”€â”€ seloger_scraper.py    # Scraper SeLoger
â”‚   â”œâ”€â”€ pap_scraper.py        # Scraper PAP
â”‚   â”œâ”€â”€ leboncoin_scraper.py  # Scraper LeBonCoin
â”‚   â””â”€â”€ manager.py            # Gestionnaire de scrapers
â”œâ”€â”€ notifier/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ email_notifier.py     # SystÃ¨me d'alertes email
â””â”€â”€ logs/
    â””â”€â”€ immobilier-scraper.log
```

## ğŸ—„ï¸ Base de DonnÃ©es

### Tables principales

**properties** : Annonces immobiliÃ¨res
- id, source, url, title, location, price, surface, rooms, DPE, etc.

**property_history** : Historique des modifications
- Suivi des changements de prix et de statut

**searches** : Recherches sauvegardÃ©es
- CritÃ¨res de recherche et rÃ©sultats

**alerts** : Alertes envoyÃ©es
- Historique des notifications

## âš™ï¸ Configuration

### Modifier les critÃ¨res de recherche

Ã‰diter `config.py`:
```python
SEARCH_CONFIG = {
    'budget_min': 200000,
    'budget_max': 500000,
    'dpe_max': 'D',
    'zones': ['Paris', 'Hauts-de-Seine', 'Val-de-Marne']
}
```

### Modifier l'intervalle de scraping

Ã‰diter `config.py`:
```python
SCHEDULER_CONFIG = {
    'interval_hours': 2,  # Scraper toutes les 2 heures
    'send_time': '09:00'  # Rapport quotidien Ã  9h
}
```

## ğŸ“Š Exemples de DonnÃ©es

Les donnÃ©es scrapÃ©es incluent:
- **Titre** : Titre de l'annonce
- **Prix** : Prix d'achat
- **Localisation** : Adresse complÃ¨te
- **Surface** : Superficie en mÂ²
- **PiÃ¨ces/Chambres** : Nombre de piÃ¨ces
- **DPE** : Performance Ã©nergÃ©tique (A-G)
- **GES** : Ã‰missions de gaz Ã  effet de serre
- **Images** : URLs des photos
- **Contact** : Informations du vendeur/agent
- **URL** : Lien vers l'annonce

## ğŸ“§ Format des Emails

Les alertes contiennent:
- Liste des propriÃ©tÃ©s correspondant aux critÃ¨res
- DÃ©tails complets (prix, surface, DPE, lien)
- SynthÃ¨se visuelle avec code couleur DPE
- Horodatage et source de l'annonce

## ğŸ”„ TÃ¢ches PlanifiÃ©es

1. **Scraping rÃ©gulier** (par dÃ©faut toutes les 2 heures)
   - RÃ©cupÃ¨re les nouvelles annonces
   - DÃ©tecte les doublons
   - Envoie alertes pour les nouveautÃ©s

2. **Rapport quotidien** (par dÃ©faut Ã  09:00)
   - Statistiques globales
   - Distribution par source
   - Distribution par statut
   - AnalysÃ© des prix

## ğŸ› ï¸ DÃ©pannage

### Email non reÃ§u
- VÃ©rifier `EMAIL_PASSWORD` dans `.env`
- VÃ©rifier que l'authentification 2FA est activÃ©e
- VÃ©rifier les logs dans `logs/immobilier-scraper.log`

### Pas de donnÃ©es scrapÃ©es
- VÃ©rifier la connexion Internet
- VÃ©rifier que les URLs des plateformes sont Ã  jour
- Consulter les logs pour les erreurs HTML

### Base de donnÃ©es corrompue
- Supprimer `database/immobilier.db`
- Relancer le script (recrÃ©era la BD)

## ğŸ“ Statuts de PropriÃ©tÃ©s

- **disponible** : Annonce active
- **contactÃ©** : Contact pris avec le vendeur
- **visitÃ©** : Visite effectuÃ©e
- **rejetÃ©** : PropriÃ©tÃ© non correspond aux besoins
- **achetÃ©** : Achat finalisÃ©

## ğŸ“ˆ AmÃ©liorations Futures

- [ ] Support de zones gÃ©ographiques personnalisÃ©es
- [ ] Scraping de l'Ã©volution des prix
- [ ] Gestion des utilisateurs multiples
- [ ] Interface web
- [ ] IntÃ©gration Google Maps
- [ ] Support des SMS
- [ ] Machine Learning pour recommandations

## ğŸ“„ Licence

Ce projet est fourni Ã  titre d'exemple Ã©ducatif.

## âš–ï¸ IMPORTANT - Respect des conditions d'utilisation

Ce scraper respecte les bonnes pratiques:
- DÃ©lais entre requÃªtes
- User-Agent appropriÃ©
- Pas de surcharge serveur
- Respect des robots.txt

VÃ©rifier toujours les conditions d'utilisation des sites avant scraping.

---

**CrÃ©Ã©** : FÃ©vrier 2026
**Email** : khadhraoui.jalel@gmail.com
